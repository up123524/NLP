{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/umar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optional\n",
    "#fixes errors with importing spacy on mac OS systems on python v3.12.6\n",
    "import ssl\n",
    "import nltk\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we are going to perform sentiment analysis on review data taken from an imdb dataset. I will attempt to use nlp to form a classification models to predict the number of positive/negative reviews.\n",
    "\n",
    "I will include samples to demonstrate what certain areas of code are doing, # indicates a line of code, ## indicates a line explaining the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import nltk\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "stopword=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis(EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the data\n",
    "imdb=pd.read_csv('/Users/umar/Documents/datasets/IMDB Dataset.csv')\n",
    "print(imdb)\n",
    "imdb.head()\n",
    "imdb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove stopwords for the dataset, stopwords are common words such as 'an' or 'are' which add little information about sentiment to the text\n",
    "#create list of stopwords in desired language\n",
    "\n",
    "#specify tokeniser\n",
    "tokeniser=ToktokTokenizer()\n",
    "\n",
    "#define our function to remove stopwords\n",
    "def remove_stopwords(rev, is_lower_case=False):\n",
    "    tokens = tokeniser.tokenize(rev) #tokenise our text using pre built tokeniser\n",
    "    tokens=[token.strip() for token in tokens] #remove whitespaces\n",
    "    if is_lower_case:\n",
    "        filter_tokens= [token for token in tokens if token not in stopwords] # we text each token against the stopword list\n",
    "    else:\n",
    "        filter_tokens = [token for token in tokens if token.lower() not in stopword] #if token is not lowercase we test the lowercase version against the stopword list\n",
    "    filtered_reviews = ' '.join(filter_tokens) # we join this futher filtered text into a list after it is parsed\n",
    "    return filtered_reviews\n",
    "\n",
    "#test corpus as an example\n",
    "#text=  \"I remember as a child, and as a young budding naturalist, spending all my time observing and testing the world around me\"\n",
    "#text_stopwords=remove_stopwords(text)\n",
    "#print('removed stopwords:', text_stopwords)\n",
    "\n",
    "imdb['review']=imdb['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#splitting the dataset for training/testing train/test \n",
    "#here I am employing the common 80:20 rule for testing\n",
    "train_sentiment=imdb['sentiment'][:40000]\n",
    "train_reviews=imdb['review'][:40000]\n",
    "test_sentiment=imdb['sentiment'][40000:]\n",
    "test_reviews=imdb['review'][40000:]\n",
    "#we should expect 0 to ensure same length of datasets\n",
    "print(len(train_reviews)-len(train_sentiment))\n",
    "print(len(test_reviews)-len(test_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a key inital step in the NLP pipeline we need to tokenise the dataset\n",
    "tokeniser=ToktokTokenizer()\n",
    "#reduce noise and increase effiency from removing stopwords\n",
    "stopwords=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pz/ppj3c3y97wb28xcmb96ybk6r0000gp/T/ipykernel_10392/3175857043.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(rev, \"html.parser\")\n"
     ]
    }
   ],
   "source": [
    "#strip additonal noise\n",
    "#remove html\n",
    "def html(rev):\n",
    "    soup = BeautifulSoup(rev, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "import re\n",
    "\n",
    "def rem_sq_brkets(rev):\n",
    "    return re.sub(r'\\[[^]]*\\]', '', rev) \n",
    "\n",
    "\n",
    "def denoise(rev):\n",
    "    rev = html(rev)\n",
    "    rev = rem_sq_brkets(rev)\n",
    "    return rev\n",
    "\n",
    "imdb['review']=imdb['review'].apply(denoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#futher denoising reviews column\n",
    "#use regex to target characters that arent in a-z,0-9, uppercase letters or a space\n",
    "def rem_special_characters(rev, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    rev=re.sub(pattern,'',rev)\n",
    "    return rev\n",
    "\n",
    "imdb['review']=imdb['review'].apply(rem_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    one review mention watch 1 oz episod hook righ...\n",
       "1    wonder littl product the film techniqu unassum...\n",
       "2    thought wonder way spend time hot summer weeke...\n",
       "3    basic famili littl boy jake think zombi closet...\n",
       "4    petter mattei love time money visual stun film...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reduce the dimenionsality of our dataset\n",
    "#We reduce words to their original formatting e.g. carrying -> carry\n",
    "#in this implementation I will be using the snowball stemmer for improved flexibility and language support\n",
    "#this will allow the code to become more flexible and take in a bigger dataset of multuple language reviews\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "##############Run this sample code to see the stemmer \n",
    "##retrieve desired stemmer\n",
    "#snowball=SnowballStemmer(\"english\")\n",
    "## Examples\n",
    "#samples= [\"carrying\", \"carry\",\"runs\", \"easily\", \"quickly\"]\n",
    "##stem our sample words by looping over text\n",
    "#for sample in samples:\n",
    "#   base=snowball.stem(sample)\n",
    "#    print(f\"{sample} -> {base}\")\n",
    "######################################################\n",
    "\n",
    "#stem our imdb text\n",
    "def stemmer(rev):\n",
    "    snow=SnowballStemmer('english')\n",
    "    rev = ' '.join([snow.stem(word) for word in rev.split()])\n",
    "    return rev\n",
    "\n",
    "############function test using sample text\n",
    "#text=  \"I remember as a child, and as a young budding naturalist, spending all my time observing and testing the world around me\"\n",
    "##stem_text=stemmer(text)\n",
    "#print(\"stemmed text:\", stem_text)\n",
    "\n",
    "imdb['review']=imdb['review'].apply(stemmer)\n",
    "imdb['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove stopwords for the dataset, stopwords are common words such as 'an' or 'are' which add little information about sentiment to the text\n",
    "#create list of stopwords in desired language\n",
    "\n",
    "#specify tokeniser\n",
    "tokeniser=ToktokTokenizer()\n",
    "\n",
    "#define our function to remove stopwords\n",
    "def remove_stopwords(rev, is_lower_case=False):\n",
    "    tokens = tokeniser.tokenize(rev) #tokenise our text using pre built tokeniser\n",
    "    tokens=[token.strip() for token in tokens] #remove whitespaces\n",
    "    if is_lower_case:\n",
    "        filter_tokens= [token for token in tokens if token not in stopwords] # we text each token against the stopword list\n",
    "    else:\n",
    "        filter_tokens = [token for token in tokens if token.lower() not in stopword] #if token is not lowercase we test the lowercase version against the stopword list\n",
    "    filtered_reviews = ' '.join(filter_tokens) # we join this futher filtered text into a list after it is parsed\n",
    "    return filtered_reviews\n",
    "\n",
    "#test corpus as an example\n",
    "#text=  \"I remember as a child, and as a young budding naturalist, spending all my time observing and testing the world around me\"\n",
    "#text_stopwords=remove_stopwords(text)\n",
    "#print('removed stopwords:', text_stopwords)\n",
    "\n",
    "imdb['review']=imdb['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one review mention watch 1 oz episod hook right exact happen meth first thing struck oz brutal unflinch scene violenc set right word go trust show faint heart timid show pull punch regard drug sex violenc hardcor classic use wordit call oz nicknam given oswald maximum secur state penitentari focus main emerald citi experiment section prison cell glass front face inward privaci high agenda em citi home mani aryan muslim gangsta latino christian italian irish scuffl death stare dodgi deal shadi agreement never far awayi would say main appeal show due fact goe show dare forget pretti pictur paint mainstream audienc forget charm forget romanc oz mess around first episod ever saw struck nasti surreal say readi watch develop tast oz got accustom high level graphic violenc violenc injustic crook guard sold nickel inmat kill order get away well manner middl class inmat turn prison bitch due lack street skill prison experi watch oz may becom comfort uncomfort view get touch darker side\n"
     ]
    }
   ],
   "source": [
    "#filtered reviews\n",
    "filtered_train_rev=imdb['review'][:40000]\n",
    "print(filtered_train_rev[0]) # tests\n",
    "filtered_test_rev=imdb['review'][40000:]\n",
    "#print(filtered_test_rev[40001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 2 1\n",
      "  1 0 0 1]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 2 1\n",
      "  0 1 1 0]\n",
      " [1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0]]\n",
      "['and' 'and dogs' 'and dogs are' 'are' 'are common' 'are common pets' 'at'\n",
      " 'at the' 'at the cat' 'barked' 'barked at' 'barked at the' 'cat'\n",
      " 'cat sat' 'cat sat on' 'cats' 'cats and' 'cats and dogs' 'common'\n",
      " 'common pets' 'dog' 'dog barked' 'dog barked at' 'dogs' 'dogs are'\n",
      " 'dogs are common' 'mat' 'on' 'on the' 'on the mat' 'pets' 'sat' 'sat on'\n",
      " 'sat on the' 'the' 'the cat' 'the cat sat' 'the dog' 'the dog barked'\n",
      " 'the mat']\n"
     ]
    }
   ],
   "source": [
    "#use a bag od words model to covert the corpus of text in a ml friendly format. This format is centered around word frequency. \n",
    "#Here we will vectorise the word corpus using the WordVectoriser from the scikit learn package we loaded \n",
    "\n",
    "#An example of how it works\n",
    "#initialise our count vectoriser\n",
    "cv=CountVectorizer(min_df=0.0,max_df=1.0, binary=False, ngram_range=(1,3))\n",
    "##min_df=minimum document frequency a word should appear in to be included in vocabulary\n",
    "##max_df=minimum document frequency a word should appear in to be included in vocabulary\n",
    "##binary=False indicates that we are condidering both the prescence(Binary=True) and the frequncy of words in the corpus\n",
    "##ngram_range indicates that the vectoriser will consider combinations of up to 3 words from the text to allow for more consideration of contextual information byt increasing the dimensionality of our model affected efficiency\n",
    "sample_doc = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog barked at the cat.\",\n",
    "    \"Cats and dogs are common pets.\"\n",
    "]\n",
    "#our sample bag of words\n",
    "bow_sample=cv.fit_transform(sample_doc)\n",
    "print(bow_sample.toarray())\n",
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words trained reviews: (40000, 6687752)\n",
      "Bag of words test reviews: (10000, 6687752)\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(min_df=0.0,max_df=1.0, binary=False, ngram_range=(1,3))\n",
    "#fit to train reviews\n",
    "cv_train_rev=cv.fit_transform(filtered_train_rev)\n",
    "#transform test reviews\n",
    "cv_test_rev=cv.transform(filtered_test_rev)\n",
    "#View outcomes\n",
    "print('Bag of words trained reviews:', cv_train_rev.shape)\n",
    "print('Bag of words test reviews:', cv_test_rev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19992804 0.26288135 0.26288135 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.26288135 0.26288135 0.26288135 0.26288135\n",
      "  0.         0.26288135 0.26288135 0.26288135 0.39985609 0.19992804\n",
      "  0.26288135 0.         0.         0.26288135]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.26288135 0.26288135 0.26288135 0.26288135 0.26288135 0.26288135\n",
      "  0.19992804 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.26288135 0.26288135 0.26288135 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.39985609 0.19992804\n",
      "  0.         0.26288135 0.26288135 0.        ]\n",
      " [0.25819889 0.25819889 0.25819889 0.25819889 0.25819889 0.25819889\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.25819889 0.25819889 0.25819889\n",
      "  0.25819889 0.25819889 0.         0.         0.         0.25819889\n",
      "  0.25819889 0.25819889 0.         0.         0.         0.\n",
      "  0.25819889 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n",
      "['and' 'and dogs' 'and dogs are' 'are' 'are common' 'are common pets' 'at'\n",
      " 'at the' 'at the cat' 'barked' 'barked at' 'barked at the' 'cat'\n",
      " 'cat sat' 'cat sat on' 'cats' 'cats and' 'cats and dogs' 'common'\n",
      " 'common pets' 'dog' 'dog barked' 'dog barked at' 'dogs' 'dogs are'\n",
      " 'dogs are common' 'mat' 'on' 'on the' 'on the mat' 'pets' 'sat' 'sat on'\n",
      " 'sat on the' 'the' 'the cat' 'the cat sat' 'the dog' 'the dog barked'\n",
      " 'the mat']\n"
     ]
    }
   ],
   "source": [
    "#Our next model is a Term Frequency-Inverse Document Frequency model (TFIDF) model.\n",
    "#Term frequency: Evaluates how frequency (number of times term appears/total number of terms in the text) a word appears in a corpus of text\n",
    "#Inverse document theory: log(total number of doc/number of documents containing the word)\n",
    "#TF-IDF=TFxIDF\n",
    "#A higher TF-IDF score indicates that a word is more important across a corpus of text, however it ignores context e.g. apple the fruit or apple the company\n",
    "\n",
    "#A sample to understand implementation\n",
    "#Initilise vectoriser\n",
    "tfidf=TfidfVectorizer(min_df=0.0,max_df=1.0,use_idf=True,ngram_range=(1,3)) #set 1-3 to keep comparisons between models\n",
    "sample_doc = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog barked at the cat.\",\n",
    "    \"Cats and dogs are common pets.\"\n",
    "]\n",
    "tfidf_sample=tfidf.fit_transform(sample_doc)\n",
    "print(tfidf_sample.toarray())\n",
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf training reviews: (40000, 6687752)\n",
      "tfidf testing reviews: (10000, 6687752)\n"
     ]
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer(min_df=0.0, max_df=1.0,use_idf=True,ngram_range=(1,3))\n",
    "\n",
    "tfidf_train_rev=tfidf.fit_transform(filtered_train_rev)\n",
    "tfidf_test_rev=tfidf.transform(filtered_test_rev)\n",
    "print('tfidf training reviews:', tfidf_train_rev.shape)\n",
    "print('tfidf testing reviews:', tfidf_test_rev.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           review sentiment\n",
      "0    great movie!  positive\n",
      "1  terrible movie  negative\n",
      "[[1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#binarise our sentiment data to trasnform categorical labels into a format machine learning can understand\n",
    "#A sample implementation\n",
    "data={'review':['great movie!', 'terrible movie'], 'sentiment':['positive', 'negative']}\n",
    "sample_data=pd.DataFrame(data)\n",
    "print(sample_data.head())\n",
    "#initialise label binariser\n",
    "lb=LabelBinarizer()#transform our sentiment data into binary format\n",
    "binarise_data=lb.fit_transform(sample_data['sentiment'])\n",
    "print(binarise_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "lb=LabelBinarizer()\n",
    "sentiment_trans=lb.fit_transform(imdb['sentiment'])\n",
    "print(sentiment_trans)\n",
    "print(sentiment_trans.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 1)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#split into train/test sets\n",
    "train_sentiment=sentiment_trans[:40000]\n",
    "test_sentiment=sentiment_trans[40000:]\n",
    "print(train_sentiment.shape)\n",
    "print(test_sentiment.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model the dataset using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=123)\n"
     ]
    }
   ],
   "source": [
    "#specify the model\n",
    "lr=LogisticRegression(penalty='l2',max_iter=500,C=1, random_state=123)\n",
    "#The penalty is the approach we are taking, in this case we are using a ridge regression model which has a heavy penalty on large weights leading to reduction in overfitting issues\n",
    "#The iteration specification gives a limit to how many parameters the model will attempt to converge\n",
    "#the C parameter is the regularisation parameter which defines the strength of the penalty. It is a positive number with a lower number defining a larger penalty and is helpful to prevent overfitting.\n",
    "#I define a random state for reproducability of results\n",
    "\n",
    "#apply to our bag of words approach\n",
    "lr_cv=lr.fit(cv_train_rev,train_sentiment)\n",
    "print(lr_cv)\n",
    "\n",
    "#fit model to tfidf approach\n",
    "lr_tfidf=lr.fit(tfidf_train_rev, train_sentiment)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n",
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Use our models to predict sentiments\n",
    "#Bag of words model\n",
    "lr_cv_pred=lr.predict(cv_test_rev)\n",
    "print(lr_cv_pred)\n",
    "#TFIDF model\n",
    "lr_tfidf_pred=lr.predict(tfidf_test_rev)\n",
    "print(lr_tfidf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression bag of words accuracy score: 0.8592\n",
      "logistic regression TFIDF accuracy score: 0.8854\n"
     ]
    }
   ],
   "source": [
    "#evaluate model accuracy\n",
    "#Bag of words model\n",
    "lr_cv_accurary_score=accuracy_score(test_sentiment, lr_cv_pred)\n",
    "print('logistic regression bag of words accuracy score:',lr_cv_accurary_score)\n",
    "#TFIDF model\n",
    "lr_tfidf_accurary_score=accuracy_score(test_sentiment, lr_tfidf_pred)\n",
    "print('logistic regression TFIDF accuracy score:',lr_tfidf_accurary_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.87      0.84      0.86      4993\n",
      "    Negative       0.85      0.88      0.86      5007\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.90      0.87      0.88      4993\n",
      "    Negative       0.88      0.90      0.89      5007\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print a classification report\n",
    "#Bag of words model\n",
    "lr_cv_report=classification_report(test_sentiment,lr_cv_pred,target_names=['Positive','Negative'])\n",
    "print(lr_cv_report)\n",
    "#TFIDF model\n",
    "lr_tfidf_report=classification_report(test_sentiment,lr_tfidf_pred, target_names=['Positive','Negative'])\n",
    "print(lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4384  623]\n",
      " [ 785 4208]]\n",
      "[[4498  509]\n",
      " [ 637 4356]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "#bag of words approach\n",
    "cv_cm=confusion_matrix(test_sentiment,lr_cv_pred,labels=[1,0])\n",
    "print(cv_cm)\n",
    "tfidf_cm=confusion_matrix(test_sentiment,lr_tfidf_pred,labels=[1,0])\n",
    "print(tfidf_cm)\n",
    "#####In the confusion matrix:\n",
    "#rows represent the actual outcome\n",
    "#columns represent the predicted outcome\n",
    "#True/False Positive(tp/fp) or True/False Negative(tn/fn)\n",
    "#key metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(max_iter=500, random_state=123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(max_iter=500, random_state=123)\n"
     ]
    }
   ],
   "source": [
    "#training model\n",
    "sgd=SGDClassifier(loss='hinge',max_iter=500,random_state=123)\n",
    "#fitting model to bag of words data\n",
    "sgd_cv=sgd.fit(cv_train_rev, train_sentiment)\n",
    "print(sgd_cv)\n",
    "#fitting model to tfidf approach data \n",
    "sgd_tfidf=sgd.fit(tfidf_train_rev,train_sentiment)\n",
    "print(sgd_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 0]\n",
      "[0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate SGD model performance on test data\n",
    "sgd_cv_pred=sgd.predict(cv_test_rev)\n",
    "print(sgd_cv_pred)\n",
    "sgd_tfidf_pred=sgd.predict(tfidf_test_rev)\n",
    "print(sgd_tfidf_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy score for Bag of words: 0.8605\n",
      "SGD Accuracy score for TDIDF: 0.8834\n"
     ]
    }
   ],
   "source": [
    "#Model Accuracy\n",
    "sgd_cv_accuracy=accuracy_score(test_sentiment, sgd_cv_pred)\n",
    "print('SGD Accuracy score for Bag of words:',sgd_cv_accuracy)\n",
    "sgd_tfidf_accuracy=accuracy_score(test_sentiment, sgd_tfidf_pred)\n",
    "print('SGD Accuracy score for TDIDF:',sgd_tfidf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.85      0.87      0.86      4993\n",
      "    Negative       0.87      0.85      0.86      5007\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.90      0.86      0.88      4993\n",
      "    Negative       0.87      0.90      0.89      5007\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#produce a classification report for the SGD models\n",
    "#Bag of Words approach\n",
    "sgd_cv_report=classification_report(test_sentiment, sgd_cv_pred, target_names=['Positive','Negative'])\n",
    "print(sgd_cv_report)\n",
    "#TFIDF approach\n",
    "sgd_tfidf_report=classification_report(test_sentiment,sgd_tfidf_pred, target_names=['Positive','Negative'])\n",
    "print(sgd_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4264  743]\n",
      " [ 652 4341]]\n",
      "[[4520  487]\n",
      " [ 679 4314]]\n"
     ]
    }
   ],
   "source": [
    "#Plot the confusion Matrices\n",
    "#Bag of Words\n",
    "sgd_cv_matrix=confusion_matrix(test_sentiment,sgd_cv_pred,labels=[1,0])\n",
    "print(sgd_cv_matrix)\n",
    "#TFIDF approacg\n",
    "sgd_tfidf_matrix=confusion_matrix(test_sentiment,sgd_tfidf_pred,labels=[1,0])\n",
    "print(sgd_tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n",
      "MultinomialNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Initialise our Model\n",
    "mnb=MultinomialNB()\n",
    "#Training for bag of words\n",
    "mnb_cv=mnb.fit(cv_train_rev, train_sentiment)\n",
    "print(mnb_cv)\n",
    "#Training for TDIDF approach\n",
    "mnb_tfidf=mnb.fit(tfidf_train_rev,train_sentiment)\n",
    "print(mnb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Use Model to make predictions on test data\n",
    "#Bag of Words approach\n",
    "mnb_cv_pred=mnb.predict(cv_test_rev)\n",
    "print(mnb_cv_pred)\n",
    "#TFIDF approach\n",
    "mnb_tfidf_pred=mnb.predict(tfidf_test_rev)\n",
    "print(mnb_tfidf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB bag of words prediction score: 0.8797\n",
      "MNB TFIDF prediction score: 0.8874\n"
     ]
    }
   ],
   "source": [
    "#test model accuracy\n",
    "#bag of words approach\n",
    "mnb_cv_accuracy=accuracy_score(test_sentiment,mnb_cv_pred)\n",
    "print('MNB bag of words prediction score:', mnb_cv_accuracy)\n",
    "#TFIDF approach\n",
    "mnb_tfidf_accuracy=accuracy_score(test_sentiment,mnb_tfidf_pred)\n",
    "print('MNB TFIDF prediction score:', mnb_tfidf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Positive,       0.87      0.90      0.88      4993\n",
      "    Negative       0.89      0.86      0.88      5007\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Positive,       0.89      0.89      0.89      4993\n",
      "    Negative       0.89      0.89      0.89      5007\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#produce classification reports\n",
    "#Bag of Words approach\n",
    "mnb_cv_report=classification_report(test_sentiment,mnb_cv_pred, target_names=['Positive,', 'Negative'])\n",
    "print(mnb_cv_report)\n",
    "#TFIDF approach\n",
    "mnb_tfidf_report=classification_report(test_sentiment,mnb_tfidf_pred, target_names=['Positive,', 'Negative'])\n",
    "print(mnb_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4326  681]\n",
      " [ 522 4471]]\n",
      "[[4450  557]\n",
      " [ 569 4424]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrices\n",
    "#Bag of Words approach\n",
    "mnb_cv=confusion_matrix(test_sentiment, mnb_cv_pred, labels=[1,0])\n",
    "print(mnb_cv)\n",
    "#TFIDF Approach\n",
    "mnb_tfidf=confusion_matrix(test_sentiment, mnb_tfidf_pred, labels=[1,0])\n",
    "print(mnb_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the SGD model performed worse than our other models.\n",
    "\n",
    "I believe that gains in model accuracy would be better realised by pursing more advanced forms of preprocessing the data such as RoBERTa (Robustly optimized BERT approach) which would allow us to better\n",
    "capture the importance of context in the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
